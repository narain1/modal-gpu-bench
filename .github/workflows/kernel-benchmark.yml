name: Kernel Benchmark

on:
  pull_request:
    branches:
      - main

jobs:
  benchmark:
    # Only run for PRs from narain1 user
    if: github.event.pull_request.user.login == 'narain1'
    runs-on: ubuntu-latest
    
    permissions:
      pull-requests: write
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Modal CLI
        run: pip install modal
      
      - name: Set Modal token
        run: |
          modal token set --token-id ${{ secrets.MODAL_TOKEN_ID }} --token-secret ${{ secrets.MODAL_TOKEN_SECRET }}
      
      - name: Run kernel benchmarks
        id: benchmark
        run: |
          echo "## ðŸš€ Kernel Benchmark Results" > benchmark_results.md
          echo "" >> benchmark_results.md
          echo "**PR #${{ github.event.pull_request.number }}** | **Commit:** \`${{ github.event.pull_request.head.sha }}\`" >> benchmark_results.md
          echo "" >> benchmark_results.md
          
          # Get changed files in kernels directory
          git fetch --unshallow
          git fetch origin main
          changed_files=$(git diff --name-only --diff-filter=AM origin/main...HEAD | grep '^kernels/' | grep -E '\.(py|cu)$' || true)
          
          if [ -z "$changed_files" ]; then
            echo "No kernel files were modified in this PR." >> benchmark_results.md
            exit 0
          fi
          
          echo "### ðŸ” Kernels Tested" >> benchmark_results.md
          echo "" >> benchmark_results.md
          
          # Function to run and benchmark a kernel
          run_kernel() {
            local script_path=$1
            local filename=$(basename "$script_path")
            
            echo "### ðŸ“Š ${filename}" >> benchmark_results.md
            echo "" >> benchmark_results.md
            echo '```' >> benchmark_results.md
            
            if modal run modal_run.py --script "${script_path}" --gpu "H100" --timeout 2 > kernel_output.txt 2>&1; then
              cat kernel_output.txt >> benchmark_results.md
              echo '```' >> benchmark_results.md
              echo "âœ… ${filename} executed successfully" >> benchmark_results.md
            else
              cat kernel_output.txt >> benchmark_results.md
              echo '```' >> benchmark_results.md
              echo "âŒ ${filename} failed to execute" >> benchmark_results.md
            fi
            
            echo "" >> benchmark_results.md
            echo "---" >> benchmark_results.md
            echo "" >> benchmark_results.md
          }
          
          # Run benchmark for each changed kernel file
          for file in $changed_files; do
            if [ -f "$file" ]; then
              run_kernel "$file"
            fi
          done
          
          echo "" >> benchmark_results.md
          echo "**GPU:** H100 | **Modal Runtime** | **Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> benchmark_results.md
      
      - name: Read benchmark results
        id: read_results
        run: |
          {
            echo 'benchmark_output<<EOF'
            cat benchmark_results.md
            echo 'EOF'
          } >> "$GITHUB_OUTPUT"
      
      - name: Comment PR with results
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = process.env.benchmark_output;
            const prNumber = context.payload.pull_request.number;

            // Check if there's already a benchmark comment
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
            });

            const botComment = comments.data.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('ðŸš€ Kernel Benchmark Results')
            );

            const commentBody = output;

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: commentBody
              });
            }
      
      - name: Ensure benchmark_results.md exists
        run: '[ -f benchmark_results.md ] || touch benchmark_results.md'
      
      - name: Upload benchmark results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: benchmark_results.md
          retention-days: 30
